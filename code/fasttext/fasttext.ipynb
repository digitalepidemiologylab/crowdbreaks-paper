{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from nltk import TweetTokenizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data\n",
    "The raw data can be found as [Data supplement/supporting information](https://www.pnas.org/content/114/52/13762/tab-figures-data) from the paper \"Critical dynamics in population vaccinating behavior\" by Pananos et al.\n",
    "\n",
    "This raw data has been processed in a way that only tweets which have 3 annotations of either positive (1), negative (-1) or neutral (0) are present in the data. Furthermore for each tweet the agreement score was computer. The cleaned data has then been exported to the file which can be found under `/data/vaccine_tweets_all.csv`.\n",
    "\n",
    "The data consists of a total of 27'906 labelled tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotator agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(os.path.join(data_path, 'vaccine_sentiment_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels['agreement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df_labels['agreement'].values\n",
    "# mean agreement\n",
    "print('Mean agreement {} with std {}'.format(np.nanmean(agg), np.nanstd(agg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a set of Twitter API keys and download the tweets using the following command:\n",
    "```\n",
    "python download_tweets.py -i ./data/vaccine_sentiment_data.csv -o ./data/tweets.jsonl --consumerkey XXX --consumersecret XXX --accesstoken XXX  --accesssecret XXX\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "Here we merge the data with the labels, tokenize the data and select only tweets with at least 3 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))','<url>',tweet)\n",
    "    tweet = re.sub('(\\@[^\\s]+)','<user>',tweet)\n",
    "    try:\n",
    "        tweet = tweet.decode('unicode_escape').encode('ascii','ignore')\n",
    "    except:\n",
    "        pass\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = []\n",
    "    with open(os.path.join(data_path, 'tweets.jsonl'), 'r') as f:\n",
    "        for line in f:\n",
    "            tweet = json.loads(line)\n",
    "            df.append({'tweet_id': int(tweet['id_str']), 'text': tweet['text']})\n",
    "    return pd.DataFrame(df)\n",
    "df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(df_labels, on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "indices = [] # indices of tweets which were used\n",
    "indices_black_list = []\n",
    "df['tweet_text_tokenized'] = ''\n",
    "count = 0\n",
    "total_count = len(df)\n",
    "for i, line in enumerate(df[['text']].values):\n",
    "    if count % 1000 == 0:\n",
    "        print('Tokenized {} out of {}'.format(count, total_count))\n",
    "    count += 1\n",
    "    try:\n",
    "        tweet = line[0].replace('\\n', '').replace('\\r', '').strip()\n",
    "    except:\n",
    "        print(\"could not parse line.\")\n",
    "        indices_black_list.append(i)\n",
    "        continue\n",
    "    tweet = tknzr.tokenize(tweet)\n",
    "    # throw away anything below 2 words\n",
    "    if not 2 < len(tweet) < 110:\n",
    "        indices_black_list.append(i)\n",
    "        continue\n",
    "    tweet = preprocess_tweet(' '.join(tweet))\n",
    "    df.loc[i, 'text_tokenized'] = tweet \n",
    "    indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of non-tokenizable tweets\n",
    "non_tokenizable = df['tweet_text_tokenized'].isnull().sum()\n",
    "tokenizable = len(df['tweet_text_tokenized']) - non_tokenizable\n",
    "print('#tweets tokenizable:\\t\\t{}\\n#tweets non-tokenizable:\\t{}'.format(tokenizable, non_tokenizable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# black listed tweets:\n",
    "df.iloc[indices_black_list].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText\n",
    "\n",
    "FastText was installed the following way:\n",
    "```\n",
    "git clone git@github.com:facebookresearch/fastText.git\n",
    "cd fastText\n",
    "pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'label'] = df['label'].apply(lambda s: '__label__'+str(s)+' ')\n",
    "df = df[['label', 'text_tokenized']]\n",
    "df.to_csv(os.path.join(data_path, 'all_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "The following command runs a grid search through hyperparameters (ngrams, dimensions, epochs, learning rate).\n",
    "A word of caution: The code produces very large ouput files (in total ~50 GB).\n",
    "```\n",
    "python ./code/fasttext/train.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(os.path.join(data_path, 'fasttext_results.csv'))\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_new = {}\n",
    "import ast\n",
    "for i, row in enumerate(results.values):\n",
    "    results_new[i] = ast.literal_eval(row[-1])\n",
    "    results_new[i]['precision'] = results.loc[i, 'precision']\n",
    "    results_new[i]['recall'] = results.loc[i, 'recall']\n",
    "    results_new[i]['f1'] = results.loc[i, 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_new = pd.DataFrame(results_new).transpose()\n",
    "results_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max precision\n",
    "results_new.iloc[results_new['precision'].values.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "color_dict = {1: 'red', 2: 'green', 3: 'blue'}\n",
    "colors = [color_dict[int(c)] for c in results_new['ngrams']]\n",
    "plt.clf()\n",
    "plt.scatter(results_new['dim'], results_new['precision'], c=colors)\n",
    "plt.xlabel('dimension')\n",
    "plt.ylabel('precision')\n",
    "plt.xlim([0,900])\n",
    "leg = [mpatches.Circle((0.5, 0.5), color=color_dict[k], label=k) for k in color_dict.keys()]\n",
    "plt.legend(handles=leg, title='ngrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {1: 'red', 2: 'green', 3: 'blue'}\n",
    "colors = [color_dict[int(c)] for c in results_new['ngrams']]\n",
    "plt.clf()\n",
    "plt.scatter(results_new['dim'], results_new['recall'], c=colors)\n",
    "plt.xlabel('dimension')\n",
    "plt.ylabel('recall')\n",
    "plt.xlim([0,900])\n",
    "leg = [mpatches.Circle((0.5, 0.5), color=color_dict[k], label=k) for k in color_dict.keys()]\n",
    "plt.legend(handles=leg, title='ngrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {1: 'red', 2: 'green', 3: 'blue'}\n",
    "colors = [color_dict[int(c)] for c in results_new['ngrams']]\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(results_new['dim'], results_new['f1'], c=colors)\n",
    "plt.xlabel('dimension')\n",
    "plt.ylabel('f1')\n",
    "plt.xlim([0,900])\n",
    "leg = [mpatches.Circle((0.5, 0.5), color=color_dict[k], label=k) for k in color_dict.keys()]\n",
    "plt.legend(handles=leg, title='ngrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {1: 'red', 2: 'green', 3: 'blue'}\n",
    "colors = [color_dict[int(c)] for c in results_new['ngrams']]\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(results_new['l'], results_new['precision'], c=colors)\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('precision')\n",
    "#     plt.xlim([0,900])\n",
    "leg = [mpatches.Circle((0.5, 0.5), color=color_dict[k], label=k) for k in color_dict.keys()]\n",
    "plt.legend(handles=leg, title='ngrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some more testing optimal learning seems to be around 0.015. The model selected has the following hyperparameters:\n",
    "```\n",
    "    Dimensions: 100\n",
    "    Epochs: 200\n",
    "    ngrams: 3\n",
    "    learning_rate: 0.015\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cb-paper]",
   "language": "python",
   "name": "conda-env-cb-paper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
